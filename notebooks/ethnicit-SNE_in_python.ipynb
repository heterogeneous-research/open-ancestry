{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What can we learn from publically available genetic data?\n",
    "\n",
    "Your DNA holds a wealth of information about your ancestry, susceptibility to diseases, and complex characteristics including height, weight, facial features, and behavior. Using publically available data from 23andMe, a direct-to-consumer genetics company, we will show how to determine the ancestry of an anonymous sample from 23andMe found online.\n",
    "\n",
    "Three things you will learn and be able to do by the end of this tutorial:\n",
    "1. How to understand and analyze genetic data from two different sources (23andMe and 1000 Genomes Project).\n",
    "2. The basics of principle component analysis, a tool for unsupervised clustering, dimensional reduction, and data exploration.\n",
    "3. How to predict ancestry from an anonymous genetic data set using principle component analysis.\n",
    "\n",
    "First, you can download a set of publically-available 23andMe data. This file is about 23Mb in size. We will use the python urllib package (link here) to download the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dm_23andme_v3_110219.txt', <httplib.HTTPMessage instance at 0x1118ba6c8>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "\n",
    "u = urllib.URLopener()\n",
    "u.retrieve(\"https://s3-eu-west-1.amazonaws.com/dm-23andme-v3/dm_23andme_v3_110219.txt\", \"dm_23andme_v3_110219.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the pandas library to load our data as a dataframe and take a look at the shape and content. The file has a number of header lines that start with '#'. We will skip these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ps14/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "anon = pd.read_table(\"../data/dm_23andme_v3_110219.txt\", sep = \"\\t\", comment = \"#\", header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many rows and columns the data has, and what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 23andMe datset has 966977 rows and 4 columns.\n",
      "            0  1       2   3\n",
      "0   rs4477212  1   72017  AA\n",
      "1   rs3094315  1  742429  AG\n",
      "2   rs3131972  1  742584  AG\n",
      "3  rs12124819  1  766409  --\n",
      "4  rs11240777  1  788822  AG\n"
     ]
    }
   ],
   "source": [
    "print(\"The 23andMe datset has {} rows and {} columns.\".format(anon.shape[0], anon.shape[1]))\n",
    "print(anon.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial, you only need to use about 1000 rows of this dataframe - you can take the first 1,000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anon = anon.iloc[0:1000,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How is Genetic Data Organized\n",
    "\n",
    "The human genome is a sequence of over 3 billion letters (called 'bases') consisting of A's, T's, G's, and C's. This 3 billion letter sequence is split up into 23 different segments called chromosomes. The largest, chromosome 1, is nearly 250 million bases long. We have two copies of our genome (one from mom, one from dad), so we each have over 6 billion letters of DNA sequence.\n",
    "\n",
    "The schematic below shows a single chromosome and how the millions of base pairs are condensed and packaged into the chromosome.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=./0321_DNA_Macrostructure.jpg>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataframe you just printed above, the second and third columns correspond to the chromosome and position. The fourth column contains the two bases at that chromosome and position. The first column is called the rsid and it is an identifier used in databases for genetic variants.\n",
    "\n",
    "All of this column naming information is in the header of the file we loaded, but we skipped it with the comment = \"#\" line above.\n",
    "\n",
    "Let's rename the columns of the dataset accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         rsid chr     pos genotype\n",
      "0   rs4477212   1   72017       AA\n",
      "1   rs3094315   1  742429       AG\n",
      "2   rs3131972   1  742584       AG\n",
      "3  rs12124819   1  766409       --\n",
      "4  rs11240777   1  788822       AG\n"
     ]
    }
   ],
   "source": [
    "anon.columns = [\"rsid\", \"chr\", \"pos\", \"genotype\"]\n",
    "print(anon.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Publically Available Genetic Data from Three Major Human Populations\n",
    "\n",
    "\n",
    "Next, we will download samples from three major groups of humans sequenced as part of the 1,000 genomes project to catalog human genetic variation across the globe. These three groups are CEU (Northern Europeans from Utah), YRI (Yoruba in Ibadan, Nigeria) and CHB/JPT (Han Chinese and Japanese in Tokyo).\n",
    "\n",
    "The first important lesson about dealing with genomic data is that it can get VERY big. The raw data generated in sequencing a single human genome covering the 6 billion or so sites is usually at least 30Gb. By reducing down to only a subset of sites that are known to vary within human populations (23andMe uses about 1 million sites), this can be reduced. The anonymous 23andMe data we are using is only 23Mb.\n",
    "\n",
    "We will use tabix, a popular tool for indexing and querying large genomic data sets in order extract the data from the sites we are interested in from the 1000 Genomes files. Tabix saves us tons of time and makes large files much more easily accessible - more info on tabix here: http://www.htslib.org/doc/tabix.html.\n",
    "\n",
    "We will download two files - one is the genetic data itself and one is an index generated by tabix that makes querying fast and low-memory. This file is compressed and about 1Gb (969Mb) in size, so depending on your internet connection it may take a few minutes to download. You don't need to unzip it - if you do decide to unzip it to check the file out, it is about 7Gb unzipped, so don't try to look at the whole thing at once!\n",
    "\n",
    "You will need to run the command 'pip install --user pytabix' to use tabix in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'urllib' has no attribute 'URLopener'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-854393a3931d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLopener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/pilot_data/paper_data_sets/a_map_of_human_variation/low_coverage/snps/YRI.low_coverage.2010_09.genotypes.vcf.gz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"YRI.low_coverage.2010_09.genotypes.vcf.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/pilot_data/paper_data_sets/a_map_of_human_variation/low_coverage/snps/YRI.low_coverage.2010_09.genotypes.vcf.gz.tbi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"YRI.low_coverage.2010_09.genotypes.vcf.gz.tbi\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'urllib' has no attribute 'URLopener'"
     ]
    }
   ],
   "source": [
    "u = urllib.URLopener()\n",
    "u.retrieve(\"ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/pilot_data/paper_data_sets/a_map_of_human_variation/low_coverage/snps/YRI.low_coverage.2010_09.genotypes.vcf.gz\", \"YRI.low_coverage.2010_09.genotypes.vcf.gz\")\n",
    "u.retrieve(\"ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/pilot_data/paper_data_sets/a_map_of_human_variation/low_coverage/snps/YRI.low_coverage.2010_09.genotypes.vcf.gz.tbi\", \"YRI.low_coverage.2010_09.genotypes.vcf.gz.tbi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tabix\n",
    "\n",
    "YRI_file = \"../data/YRI.low_coverage.2010_09.genotypes.vcf.gz\"\n",
    "yri = tabix.open(YRI_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genetic coordinates are usually zero-based, meaning that the first base in a sequence will be 'between' position zero and position one. Below, we will check the YRI data set for the rs3094315 variant by querying sites on chromosome 1 betwen position 742428 and 742429 (this will be the 742429th base in the sequence). A simple graphic showing the difference between zero-based vs 1-based coordinates is below, taken from the following biostars post: https://www.biostars.org/p/84686/\n",
    "\n",
    "Please note, this tutorial has been updated for Python 3, so we use the `__next__()` method of tabix. If you are using Python 2.7 then use `next()` instead! Thanks to Matthew Wipperman from Memorial Sloan Kettering Cancer Center for discovering this and finding the fix!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=./basic_diagram.jpg>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rs3094315 is the second variant in our 23andMe data set and it has also been sequenced in the YRI data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rs3094315 = yri.query(\"1\", 742428, 742429)  # an iterator object\n",
    "print(rs3094315.__next__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we read the output above? As you may have noticed, it is quite a bit different that the way our 23andMe data is organized.\n",
    "\n",
    "The 1000 Genomes files are stored in VCF (variant call format) files, which is different from the format 23andMe provides, so we will need to do some data-wrangling to make the two work together. \n",
    "\n",
    "From left to right, the first five columns encode the chromosome, position, rsid, reference base (this is the letter that we expect to see most of the time), the alternate base (this is the letter that is the 'variant' which is present in some members of the population). More information on the information that is contained in a VCF can be found here: http://www.1000genomes.org/wiki/Analysis/vcf4.0/. This is one of the most common file formats in genetics and much of the additional data besides the genotypes themselves can be used to filter data to improve quality. To take a look at the VCF, you can make a copy of the bgzipped VCF you downloaded, unzip it, and use 'less' on the command line to take a look. The file is almost 7Gb once unzipped.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The final column of the VCF and (the last entry of this list) shows the genotype of each of the 59 YRI samples included in this final. The last 59 entries in the list all follow a similar format for reporting the genotype that is colon separated. For now, we are only interested in the first piece of information which is the genotype (it will be 0|0, 1|0, 0|1, or 1|1).\n",
    "\n",
    "As you can see above, our anonymous sample's genotype at this site is AG which corresponds to a 1|0 in the format listed above. 0 is the reference (G) and 1 is the alt (A). A few of the YRI samples are 1|1 which means they are AA at this site, while the YRI samples that are 0|0 are GG at this site. Before we go much further, we want to convert our 23andMe data to more closely match the format of the population reference we just downloaded by adding a column showing the genotype in the 0 and 1 format used in the 1000 Genomes VCF file (this is more common than the format 23andMe uses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_anon_genotype(chr, pos, genotype, vcf_tabix):\n",
    "    site = vcf_tabix.query(chr, pos - 1, pos)\n",
    "    try:\n",
    "        row = site.__next__() # this will throw an error (which is caught by 'except' on the next line) if the site we queried is not in the tabix file\n",
    "    except StopIteration:\n",
    "        return None # put None in the dataframe if we are missing this genotype in 1000 Genomes\n",
    "    ref = row[3]\n",
    "    alt = row[4]\n",
    "    if genotype == ref+ref:\n",
    "        return(\"0|0\")\n",
    "    elif (genotype == ref+alt) | (genotype == alt+ref):\n",
    "        return(\"0|1\")\n",
    "    elif genotype == alt+alt:\n",
    "        return(\"1|1\")\n",
    "    else: # missing genotype, or incorrect annotation, we assume ref/ref\n",
    "        return(\"0|0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yri' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-bdc30208a0f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgenotypes_1kg_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenotype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'chr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'genotype'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mgenotypes_1kg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_anon_genotype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenotype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0manon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'genotype_1kg_format'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenotypes_1kg_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'yri' is not defined"
     ]
    }
   ],
   "source": [
    "genotypes_1kg_format = []\n",
    "for chr, pos, genotype in zip(anon['chr'], anon['pos'], anon['genotype']):\n",
    "    genotypes_1kg_format.append(convert_anon_genotype(str(chr), pos, genotype, yri))\n",
    "\n",
    "anon['genotype_1kg_format'] = genotypes_1kg_format\n",
    "print(anon.head())\n",
    "print(anon.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Featurespace from our Genotypes\n",
    "\n",
    "We want to express the genetic data as a feature space with the first goal in mind of predicting ancestry. We will build a dataframe where our rows are the samples (people) and we treat the genotype at each chromosome and position as a separate feature. Since we restricted the anonymous 23andMe sample to the first thousand sites, our dataframe will have two columns describing the population and a name for each sample, plus another 1000 columns (one for each feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  population sample\n",
      "0        YRI   YRI1\n",
      "1        YRI   YRI2\n",
      "2        YRI   YRI3\n",
      "3        YRI   YRI4\n",
      "4        YRI   YRI5\n"
     ]
    }
   ],
   "source": [
    "# make a data frame with one row for each of the YRI samples\n",
    "yri_genotypes = pd.DataFrame({\"sample\": [\"YRI\" + str(i) for i in range(1, 60)], \"population\": \"YRI\"})\n",
    "print(yri_genotypes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the genotype from each person, we will write a function that uses pytabix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract genotype information for a set of sites\n",
    "def extract_genotype(chr, pos, vcf_tabix):\n",
    "    site = vcf_tabix.query(chr, pos - 1, pos)\n",
    "    try:\n",
    "        g = site.__next__()[9:]\n",
    "    except StopIteration:\n",
    "        return None # put None in the dataframe if we are missing this genotype in 1000 Genomes\n",
    "    g = [i.split(\":\")[0] for i in g]  # if present in 1000 genomes, get the genotypes\n",
    "    return(g)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yri' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4ff3987d594f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrsid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rsid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'chr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_genotype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0myri_genotypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrsid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'yri' is not defined"
     ]
    }
   ],
   "source": [
    "for rsid, chr, pos in zip(anon['rsid'], anon['chr'], anon['pos']):\n",
    "    g = extract_genotype(str(chr), pos, yri)\n",
    "    yri_genotypes[rsid] = g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataframe including all of the samples from the YRI population has 59 samples and 0 genotypes.\n"
     ]
    }
   ],
   "source": [
    "print(\"The dataframe including all of the samples from the YRI population has {} samples and {} genotypes.\".format(yri_genotypes.shape[0], yri_genotypes.shape[1] - 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the columns with 'None' are sites that were sequenced by 23andMe, but not present in our YRI data set. Later, we will discard all of the sites where we have missing data in any of our populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  population sample\n",
      "0        YRI   YRI1\n",
      "1        YRI   YRI2\n",
      "2        YRI   YRI3\n",
      "3        YRI   YRI4\n",
      "4        YRI   YRI5\n",
      "5        YRI   YRI6\n",
      "6        YRI   YRI7\n",
      "7        YRI   YRI8\n",
      "8        YRI   YRI9\n",
      "9        YRI  YRI10\n"
     ]
    }
   ],
   "source": [
    "print(yri_genotypes.iloc[0:10, 0:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will download data sets and make data frames for the CEU (European from Utah) and CHB/JPT (Han Chinese/Japanese). Again, curl or wget should be used from the command line to download these files and the tabix indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'urllib' has no attribute 'URLopener'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a6c726073393>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLopener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/pilot_data/paper_data_sets/a_map_of_human_variation/low_coverage/snps/CEU.low_coverage.2010_09.genotypes.vcf.gz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CEU.low_coverage.2010_09.genotypes.vcf.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/pilot_data/paper_data_sets/a_map_of_human_variation/low_coverage/snps/CEU.low_coverage.2010_09.genotypes.vcf.gz.tbi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CEU.low_coverage.2010_09.genotypes.vcf.gz.tbi\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/pilot_data/paper_data_sets/a_map_of_human_variation/low_coverage/snps/CHBJPT.low_coverage.2010_09.genotypes.vcf.gz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CHBJPT.low_coverage.2010_09.genotypes.vcf.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/pilot_data/paper_data_sets/a_map_of_human_variation/low_coverage/snps/CHBJPT.low_coverage.2010_09.genotypes.vcf.gz.tbi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CHBJPT.low_coverage.2010_09.genotypes.vcf.gz.tbi\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'urllib' has no attribute 'URLopener'"
     ]
    }
   ],
   "source": [
    "u = urllib.URLopener()\n",
    "u.retrieve(\"ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/pilot_data/paper_data_sets/a_map_of_human_variation/low_coverage/snps/CEU.low_coverage.2010_09.genotypes.vcf.gz\", \"CEU.low_coverage.2010_09.genotypes.vcf.gz\")\n",
    "u.retrieve(\"ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/pilot_data/paper_data_sets/a_map_of_human_variation/low_coverage/snps/CEU.low_coverage.2010_09.genotypes.vcf.gz.tbi\", \"CEU.low_coverage.2010_09.genotypes.vcf.gz.tbi\")\n",
    "u.retrieve(\"ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/pilot_data/paper_data_sets/a_map_of_human_variation/low_coverage/snps/CHBJPT.low_coverage.2010_09.genotypes.vcf.gz\", \"CHBJPT.low_coverage.2010_09.genotypes.vcf.gz\")\n",
    "u.retrieve(\"ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/pilot_data/paper_data_sets/a_map_of_human_variation/low_coverage/snps/CHBJPT.low_coverage.2010_09.genotypes.vcf.gz.tbi\", \"CHBJPT.low_coverage.2010_09.genotypes.vcf.gz.tbi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tabix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-297af9d08c52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# europeans from utah\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mCEU_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../data/CEU.low_coverage.2010_09.genotypes.vcf.gz\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mceu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtabix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCEU_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnumber_ceu_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mceu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m742428\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m742429\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tabix' is not defined"
     ]
    }
   ],
   "source": [
    "# europeans from utah\n",
    "CEU_file = \"../data/CEU.low_coverage.2010_09.genotypes.vcf.gz\"\n",
    "ceu = tabix.open(CEU_file)\n",
    "\n",
    "number_ceu_samples = len(ceu.query(\"1\", 742428, 742429).__next__()[9:])\n",
    "\n",
    "ceu_genotypes = pd.DataFrame({\"sample\": [\"CEU\" + str(i) for i in range(1, number_ceu_samples + 1)], \"population\": \"CEU\"})\n",
    "\n",
    "# Han chinese and Japanese\n",
    "CHBJPT_file = \"../data/CHBJPT.low_coverage.2010_09.genotypes.vcf.gz\"\n",
    "chbjpt = tabix.open(CHBJPT_file)\n",
    "\n",
    "number_chbjpt_samples = len(chbjpt.query(\"1\", 742428, 742429).__next__()[9:])\n",
    "\n",
    "chbjpt_genotypes = pd.DataFrame({\"sample\": [\"CHBJPT\" + str(i) for i in range(1, number_chbjpt_samples + 1)], \"population\": \"CHBJPT\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yri' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b8df36d3b005>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrsid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rsid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'chr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0myri_genotypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrsid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mextract_genotype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mceu_genotypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrsid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mextract_genotype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mchbjpt_genotypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrsid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mextract_genotype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchbjpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'yri' is not defined"
     ]
    }
   ],
   "source": [
    "for rsid, chr, pos in zip(anon['rsid'], anon['chr'], anon['pos']):\n",
    "    yri_genotypes[rsid] =  extract_genotype(str(chr), pos, yri)\n",
    "    ceu_genotypes[rsid] =  extract_genotype(str(chr), pos, ceu)\n",
    "    chbjpt_genotypes[rsid] =  extract_genotype(str(chr), pos, chbjpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have three separate dataframes from our three populations of interest containing their genotype at 1000 different locations. Our goal is to see how well we can separate the samples into populations based only on their genetic information, ignoring the original population labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ceu_genotypes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-439460f760a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgenotypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myri_genotypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenotypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenotypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mceu_genotypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgenotypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenotypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchbjpt_genotypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Now the genotypes data frame has {} samples and {} genotypes\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenotypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenotypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ceu_genotypes' is not defined"
     ]
    }
   ],
   "source": [
    "genotypes = yri_genotypes.copy()\n",
    "genotypes = genotypes.append(ceu_genotypes, ignore_index=True)\n",
    "genotypes = genotypes.append(chbjpt_genotypes, ignore_index=True)\n",
    "\n",
    "print(\"Now the genotypes data frame has {} samples and {} genotypes\".format(genotypes.shape[0], genotypes.shape[1]-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using t-SNE to do ancestry prediction\n",
    "\n",
    "This medium post does a great job describing the differences between PCA and t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'genotypes_only' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b4974c98d306>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperplexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0monekg_tsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenotypes_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'genotypes_only' is not defined"
     ]
    }
   ],
   "source": [
    "for p in [10, 100, 300]:\n",
    "    tsne = TSNE(perplexity = p)\n",
    "    onekg_tsne = tsne.fit_transform(genotypes_only)\n",
    "    plt.figure(figsize=(10,6))\n",
    "\n",
    "    for c, pop in zip(\"rgb\", [\"YRI\", \"CEU\", \"CHBJPT\"]):\n",
    "        plt.scatter(onekg_tsne[np.where(genotypes['population'] == pop), 0], onekg_tsne[np.where(genotypes['population'] == pop), 1], c = c, label = pop)\n",
    "\n",
    "    # take the code above and add in the anonymous sample\n",
    "\n",
    "    #plt.scatter(anon_pca[0,0], anon_pca[0,1], c = \"yellow\", label = \"Anonymous 23andMe Sample\", marker = (5,1,0), s = 200)\n",
    "\n",
    "    plt.title('t-SNE of 1000 23andMe SNPs, perplexity = {}'.format(p))\n",
    "    plt.xlabel('dim 1')\n",
    "    plt.ylabel('dim 2')\n",
    "    plt.legend(loc = 'upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the plot above, t-SNE works as well as PCA!\n",
    "\n",
    "One big drawback, however, is that t-SNE does not naturally keep track of the 'loadings'. This means that taking a new piece of data and mapping it onto the reduced dimension space is very difficult.\n",
    "\n",
    "However, there has been some suggestion that it is possible (but still difficult) to do this using deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Written by: Patrick is a PhD Student in Mathematical Genomics and Medicine at the University of Cambridge and the Wellcome Trust Sanger Institute. Before his PhD, Patrick studied Applied Mathematics and Quantitative Biology at the University of North Carolina, Chapel Hill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
